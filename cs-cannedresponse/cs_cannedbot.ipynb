{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canned-response Chatbot\n",
    "\n",
    "This notebook creates, trains, and initializes a chatbot returns canned responses to the user.  \n",
    "The model uses the DNN class from tflearn and parses input into a bag-of-words.  \n",
    "\n",
    "The model is then implemented in a function which replicates a simple customer-service chatbot at a bank.  \n",
    "\n",
    "More information and another example can be found in [this url](https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't already, copy the repo to your environment and install /CustomerServiceBot-RW/cs-cannedresponse/requirements.txt\n",
    "\n",
    "!git clone https://github.com/rweddell/CustomerServiceBot-RW\n",
    "!pip install -r /CustomerServiceBot-RW/cs-cannedresponse/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, pickle, json, re, string, tflearn, spacy, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os import path, name, system\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from random import choice, randint, uniform\n",
    "import numpy as np \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opens the training file and stores in a dictionary. This dictionary will be referenced throughout the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cs_prompts.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesses and formats the training data. It builds a bag of words for each point in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    stemmer = LancasterStemmer()\n",
    "\n",
    "    words = []\n",
    "    labels = list(data.keys())\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for label in labels:\n",
    "        for pattern in data[label]['patterns']:\n",
    "            tokens = nltk.word_tokenize(pattern)\n",
    "            words.extend(tokens)\n",
    "            docs_x.append(tokens)\n",
    "            docs_y.append(label)\n",
    "\n",
    "    # Pass over punctuation tokens\n",
    "    ignored_tokens = [',', '.', '?', '!']\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w not in ignored_tokens]\n",
    "\n",
    "    words = sorted(set(words))\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    # Template for the BOW\n",
    "    out_empty = list(np.zeros(len(labels)))\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "        stemmed = [stemmer.stem(w) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in stemmed:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)  \n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)    \n",
    "    \n",
    "    return words, labels, training, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed data can be stored in a pickle file for later use. If a pickle file of training data already exists, it will be read and used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists('./data.pickle'):\n",
    "    # If a pickle file of the processed training data exists, then it will be loaded\n",
    "    with open('data.pickle', 'rb') as file:\n",
    "        words, labels, training, output = pickle.load(file)\n",
    "else:\n",
    "    # If no pickle file exists, the training data will be processed and saved in a pickle file\n",
    "    words, labels, training, output = preprocess_data(data)\n",
    "    with open('data.pickle', 'wb') as file:\n",
    "        pickle.dump((words, labels, training, output), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model\n",
    "The DNN is created using TFlearn, which is built on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may or may not be required depending on your environment\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create and train a new model\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(training, output, n_epoch=500, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencing a pretrained model\n",
    "If a model has already been created and saved in a file, the following cell will pull the model into an object. This allows you to avoid constantly retraining the DNN every time the notebook is opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load a previously trained model\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.load('model.tflearn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(): \n",
    "    # Uses os.system and os.name\n",
    "    # for windows \n",
    "    if name == 'nt': \n",
    "        _ = system('cls') \n",
    "    # for mac/linux \n",
    "    else: \n",
    "        _ = system('clear') \n",
    "\n",
    "def bag_of_words(s, words, stemmer):\n",
    "    # Creates a bag of words from a given sequence of tokens\n",
    "    bag = list(np.zeros(len(words)))\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i]=1\n",
    "    return np.array(bag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chat Function\n",
    "The model is implemented within a function. It frames a system of rules to interpret the intent of the user and to determine a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    with open(\"user_contacts.json\") as h_file:\n",
    "        user_contacts = json.load(h_file)\n",
    "    CHAT_ENDED = False\n",
    "    USER_NAME = '' \n",
    "    USER_PHONE = ''\n",
    "    greeting = choice(data['greeting']['responses'])\n",
    "    stemmer = LancasterStemmer()\n",
    "\n",
    "    # Named Entity Recogntion\n",
    "    ner = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def filter_punctuation(s):\n",
    "        # Uses regular expressions to filter non-alphabetical characters from strings\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        return regex.sub('', s)\n",
    "\n",
    "    def classify(user_input):\n",
    "        results = model.predict([bag_of_words(user_input, words, stemmer)])\n",
    "        prediction = labels[np.argmax(results)]\n",
    "        response = choice(data[prediction]['responses'])\n",
    "        return prediction, response\n",
    "\n",
    "    def end_chat(inp):\n",
    "        if inp.lower() in ['end', 'quit', 'stop']:\n",
    "            CHAT_ENDED = True\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_confirmation(inp):\n",
    "        prediction, response = classify(inp.lower())\n",
    "        print(f\"Bot: {response}\")\n",
    "        if prediction == 'confirm':\n",
    "            return True\n",
    "        else:\n",
    "            return False  \n",
    "        \n",
    "    def get_information(check_pos, check_info, user_name):\n",
    "        print(f\"Bot: Please give me your {check_info}.\")\n",
    "        inp = input(\"You:\")\n",
    "        if end_chat(inp):\n",
    "            return None\n",
    "        else:\n",
    "            parts = ner(inp)\n",
    "            helper = []\n",
    "            for part in parts:\n",
    "                if part.pos_ == check_pos:\n",
    "                    helper.append(part.text)\n",
    "            user_info = ' '.join(helper)\n",
    "            print(f\"Bot: Your {check_info} is {user_info}. Is that correct?\")\n",
    "            confirmation_inp = filter_punctuation(input(\"You:\").lower())\n",
    "\n",
    "            if end_chat(confirmation_inp):\n",
    "                return None\n",
    "\n",
    "            confirmed = get_confirmation(confirmation_inp)\n",
    "\n",
    "            if not confirmed:\n",
    "                return None\n",
    "        \n",
    "        if check_info == 'first and last name':\n",
    "            # Make a new entry in user_contact\n",
    "            if user_info != '' and user_info not in user_contacts.keys():\n",
    "                user_contacts[user_info] = {'phone':'','requests':[]}\n",
    "        else:\n",
    "            user_contacts[user_name] = {'phone':user_info,'requests':[]}\n",
    "        return user_info\n",
    "            \n",
    "            \n",
    "    clear()\n",
    "\n",
    "    print(f\"Bot: {greeting}\")\n",
    "\n",
    "    while not CHAT_ENDED:\n",
    "        prediction = None\n",
    "        inp = filter_punctuation(input(\"You:\").lower())\n",
    "        if end_chat(inp):\n",
    "            break\n",
    "\n",
    "        prediction, response = classify(inp)\n",
    "        \n",
    "        if inp == '':\n",
    "            print(\"Bot: I'm sorry, I didn't quite get that.\")\n",
    "            \n",
    "        elif prediction == 'deny':\n",
    "            # Special case for when the bot has asked if the user needs more help\n",
    "            response = choice(data['goodbye']['responses'])\n",
    "            \n",
    "        else:\n",
    "            print(f\"Bot: {response}\")\n",
    "\n",
    "            if prediction in ['open_account', 'close_account', 'account_balance']:\n",
    "                confirmation_inp = filter_punctuation(input(\"You:\").lower())\n",
    "                if end_chat(confirmation_inp):\n",
    "                    break\n",
    "\n",
    "                confirmed = get_confirmation(confirmation_inp)\n",
    "\n",
    "                if confirmed:\n",
    "                    # User wants to manage their account\n",
    "                    print(f\"Bot: {choice(data[prediction]['confirmed'])}\")\n",
    "                    # NER looks for words that begin with capital letters\n",
    "                    USER_NAME = get_information('PROPN', 'first and last name', USER_NAME)\n",
    "                    if USER_NAME is not None:\n",
    "                        USER_PHONE = get_information('NUM', 'phone number', USER_NAME)\n",
    "                        if USER_PHONE is not None:\n",
    "                            if prediction in ['open_account', 'close_account']:\n",
    "                                message = f\"Bot: A request has been logged for {USER_NAME} to '{prediction.replace('_', ' ')}'.\"\n",
    "                                user_contacts[USER_NAME]['requests'].append(prediction)\n",
    "                            elif prediction == 'account_balance':\n",
    "                                # Print a random float between 1 and 9999999\n",
    "                                balance = round(uniform(1,9999999), 2)\n",
    "                                message = f\"Bot: Your account balance is ${balance}\"\n",
    "\n",
    "                            print(message)\n",
    "\n",
    "                    USER_NAME = ''\n",
    "                    USER_PHONE = ''\n",
    "\n",
    "            elif prediction == 'goodbye' or prediction == 'deny':\n",
    "                break\n",
    "        \n",
    "        if not CHAT_ENDED:\n",
    "            print(\"Bot: What else I can help with?\")\n",
    "\n",
    "    with open(\"user_contacts.json\", \"w\") as h_file:\n",
    "        json.dump(user_contacts, h_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example chat log\n",
    "\n",
    "Bot: Hi there, how can I help?  \n",
    "You: Open a new account  \n",
    "Bot: You are trying to open an account. Is that correct?  \n",
    "You: Yes  \n",
    "Bot: Thanks for the confirmation.  \n",
    "Bot: You will need to speak with a representative, but I can log a request to speed up the process.  \n",
    "Bot: Please give me your first and last name.  \n",
    "You: My name is Lester Morrison  \n",
    "Bot: Your first and last name is Lester Morrison. Is that correct?  \n",
    "You: Correct  \n",
    "Bot: Thank you.  \n",
    "Bot: Please give me your phone number.  \n",
    "You: 3847394742  \n",
    "Bot: Your phone number is 3847394742. Is that correct?  \n",
    "You: Yes  \n",
    "Bot: Thanks.  \n",
    "Bot: A request has been logged for Lester Morrison to 'open account'  \n",
    "Bot: Is there anything else I can help with?  \n",
    "You: What are the hours of operation?  \n",
    "Bot: All BotBank locations are open 7am-4pm Monday-Friday!  \n",
    "Bot: Is there anything else I can help with?  \n",
    "You: No that's all  \n",
    "Bot: Glad I could help. Thanks for choosing BotBank Have a nice day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
