{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# \n",
    "#https://www.youtube.com/watch?v=k1SzvvFtl4w\n",
    "#https://www.youtube.com/watch?v=wypVcNIH6D4\n",
    "#https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751\n",
    "# https://realpython.com/python-keras-text-classification/\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import path\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from random import choice, randint\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import nltk, pickle, json, re, string, tflearn, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cs_prompts.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and format the training data\n",
    "def preprocess_train_data(data):\n",
    "    stemmer = LancasterStemmer()\n",
    "\n",
    "    words = []\n",
    "    labels = list(data.keys())\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for label in labels:\n",
    "        for pattern in data[label]['patterns']:\n",
    "            tokens = nltk.word_tokenize(pattern)\n",
    "            words.extend(tokens)\n",
    "            docs_x.append(tokens)\n",
    "            docs_y.append(label)\n",
    "\n",
    "    # Pass over punctuation tokens\n",
    "    ignored_tokens = [',', '.', '?', '!']\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w not in ignored_tokens]\n",
    "\n",
    "    words = sorted(set(words))\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    # Template for the BOW\n",
    "    out_empty = list(np.zeros(len(labels)))\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "        stemmed = [stemmer.stem(w) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in stemmed:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)  \n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)    \n",
    "    \n",
    "    return words, labels, training, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a pickle file of the processed training data exists, then it will be loaded\n",
    "# Otherwise, the training data will be processed and saved in a pickle file\n",
    "\n",
    "if path.exists('./data.pickle'):\n",
    "    words, labels, training, output = preprocess_train_data(data)\n",
    "    with open('data.pickle', 'wb') as file:\n",
    "        pickle.dump((words, labels, training, output), file)\n",
    "else:\n",
    "    with open('data.pickle', 'rb') as file:\n",
    "        words, labels, training, output = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create and train a new model\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(training, output, n_epoch=500, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load a previously trained model\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.load('model.tflearn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, words, stemmer):\n",
    "    bag = list(np.zeros(len(words)))\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i]=1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(): \n",
    "    from os import system, name\n",
    "    # for windows \n",
    "    if name == 'nt': \n",
    "        _ = system('cls') \n",
    "    # for mac and linux \n",
    "    else: \n",
    "        _ = system('clear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "\n",
    "    clear()\n",
    "    greetings = [\"Hello! How can I help you today?\", \"Hello! What do you need help with today?\", \"Hi there, how can I help?\"]\n",
    "    print(choice(greetings))\n",
    "\n",
    "    stemmer = LancasterStemmer()\n",
    "    user_first_name = None\n",
    "    user_last_name = None\n",
    "    user_account_number = None\n",
    "\n",
    "    def filter_punctuation(s):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        return regex.sub('', s)\n",
    "\n",
    "    while True:\n",
    "        prediction = None\n",
    "\n",
    "        inp = filter_punctuation(input(\"You: \"))\n",
    "        print(inp)\n",
    "        if inp.lower() in ['quit', 'exit', 'stop']:\n",
    "            break\n",
    "\n",
    "        results = model.predict([bag_of_words(inp, words, stemmer)])\n",
    "        \n",
    "        result_index = np.argmax(results)\n",
    "        \n",
    "        result_max = np.max(results)\n",
    "\n",
    "        if result_max > 0.66:\n",
    "\n",
    "            prediction = labels[result_index]\n",
    "\n",
    "            responses = data[prediction]['responses']\n",
    "                    \n",
    "            response = choice(responses)\n",
    "\n",
    "            # print(prediction)\n",
    "\n",
    "            print('Bot: ', choice(responses))\n",
    "\n",
    "            if prediction in ['open_account', 'close_account', 'transfer_funds']:\n",
    "                \n",
    "                print(\"Bot: Please give me your first and last name.\")\n",
    "\n",
    "                inp = input(\"You: \")\n",
    "\n",
    "                user_first_name, user_last_name = inp.split()\n",
    "\n",
    "                print(f'Bot: Thank you, {user_first_name}.')\n",
    "\n",
    "                if prediction == 'open_account':\n",
    "\n",
    "                    user_account_number = ''.join([str(randint(1,9)) for i in range(12)])\n",
    "\n",
    "                    print(f'Bot: Here is your new account number: {user_account_number}')\n",
    "\n",
    "                    print('Bot: Can I help with anything else?')\n",
    "\n",
    "                else:\n",
    "                    print('Please give me your account number.')\n",
    "\n",
    "                    inp = input(\"You: \")\n",
    "\n",
    "                    print(f'Bot: Thank you, {user_first_name}. I have your account number')\n",
    "\n",
    "                    print('Bot: Your requested action has taken place.')\n",
    "\n",
    "                    print('Bot: Can I help with anything else?')\n",
    "                    \n",
    "        if prediction is 'goodbye':\n",
    "            break\n",
    "\n",
    "        if prediction is None:\n",
    "            print(f\"Bot: I'm sorry, I didn't quite get that. Can you rephrase your question?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}