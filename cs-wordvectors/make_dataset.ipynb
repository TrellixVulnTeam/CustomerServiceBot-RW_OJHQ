{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c9c193319ebd2a89754c1a4aa4516d58b41ef9df354ad04f80777c68efefc770"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Making your dataset\n",
    "This notebook contains some logic that can be used to format a text file of conversations to the format required by PersonaChat.\n",
    "The text file should have conversations made of lines of dialogue alternating between two speakers.  \n",
    "Each utterance of dialogue should be on a separate line.\n",
    "The conversations should be separated by a single newline.  \n",
    "Each conversation should begin with Speaker1, the customer, followed by speaker2, the bot.\n",
    "\n",
    "Example conversation format:\n",
    "```\n",
    "hours of operation  \n",
    "All BotBank locations are open 7am to 4pm monday through friday! What else I can help with?  \n",
    "that's all  \n",
    "Thank you for using BotBank.  \n",
    "\n",
    "what are the hours?  \n",
    "All BotBank locations are open 7am to 4pm monday through friday! What else I can help with?  \n",
    "thats all I needed  \n",
    "Glad I could help. Thanks for choosing BotBank Have a nice day.  \n",
    "```\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import choice"
   ]
  },
  {
   "source": [
    "Read from a text file of conversations.   \n",
    "The format must be as described above, and relies on a double newline character ('\\n\\n') to divide conversations.  \n",
    "Parse the conversations into a list of lists.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hi i want to close my account .',\n",
       " 'you wish to close an existing account . is that correct ?',\n",
       " 'thats right .',\n",
       " 'i can log a request to speed up the process . please give me your first and last name .',\n",
       " 'my name is <f_name> <l_name>',\n",
       " 'your first and last name is <f_name> <l_name> . is that correct ?',\n",
       " 'correct .',\n",
       " 'a request has been logged . is there anything else i can help with ?',\n",
       " 'thats all .',\n",
       " 'thank you for using botbank .']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "with open('conversations.txt') as txt:\n",
    "    data = txt.read()\n",
    "\n",
    "convos = data.split('\\n\\n')\n",
    "convo_list = []\n",
    "\n",
    "for convo in convos:\n",
    "    fixed = convo.lower()\n",
    "    fixed = fixed.replace('.', ' .').replace(',', '').replace('?', ' ?').replace('!', ' !').replace(\"'\", \"\")\n",
    "    convo_list.append(fixed.split('\\n'))\n",
    "\n",
    "convo_list[1]"
   ]
  },
  {
   "source": [
    "Additional text is required to fill the 'candidates' section of the training data.  \n",
    "Reads from a text file of replies from a financial question and answer dataset.   \n",
    "Replies of length > 100 and of length < 40 are filtered from the data.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['but it depends on the circumstances and what it is you want to deduct',\n",
       " 'expenses must be reasonable and appropriate deductions for extravagant expenses are not allowable',\n",
       " 'more information is available in publication 463 travel entertainment gift and car expenses',\n",
       " 'more discussion of the rules and limitations can be found in publication 463',\n",
       " 'edit for meal expenses amount of standard meal allowance']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "distractors = []\n",
    "with open('financial_responses.txt') as e_file:\n",
    "    replies = e_file.readlines()\n",
    "    for reply in replies:\n",
    "        if len(reply) < 100 and len(reply)> 40:\n",
    "            distractors.append(reply.replace('\\n', ''))\n",
    "distractors[:5]"
   ]
  },
  {
   "source": [
    "The chatbot created by Hugging Face uses a persona to apply some context to its replies.  \n",
    "The following cell establishes the personality of the chatbot.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality = [\n",
    "    \"i am here help you with your questions and requests .\",\n",
    "    \"i am a customer support helper for BotBank .\",\n",
    "    \"botbank is a globally trusted financial institution .\",\n",
    "    \"botbank offers a wide variety of financial services .\",\n",
    "    \"i am a customer support engine .\",\n",
    "    \"i cannnot do some things that my human counter parts can but i can still help .\"\n",
    "]"
   ]
  },
  {
   "source": [
    "Divide the data into training and validation sets, include the persona and distractors, and transpose the conversations into sections.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "train = []\n",
    "\n",
    "train_length = int(len(convo_list) * 0.8)\n",
    "\n",
    "for i in range(train_length):\n",
    "    helper = {}\n",
    "    convo = convo_list[i]\n",
    "    helper['personality'] = personality\n",
    "    utts = []\n",
    "    for i in range(0,len(convo)-1,2):\n",
    "        utterance = {}\n",
    "        utterance['candidates'] = [choice(e_trim) for i in range(5)]\n",
    "        utterance['candidates'].append(convo[i+1])\n",
    "        utterance['history'] = convo[:i+1]\n",
    "        utts.append(utterance)\n",
    "    helper['utterances'] = utts\n",
    "    train.append(helper)\n",
    "\n",
    "validate = []\n",
    "for i in range(train_length, len(convo_list)):\n",
    "    helper = {}\n",
    "    convo = convo_list[i]\n",
    "    helper['personality'] = personality\n",
    "    utts = []\n",
    "    for i in range(0,len(convo)-1,2):\n",
    "        utterance = {}\n",
    "        utterance['candidates'] = [choice(e_trim) for i in range(5)]\n",
    "        utterance['candidates'].append(convo[i+1])\n",
    "        utterance['history'] = convo[:i+1]\n",
    "        utts.append(utterance)\n",
    "    helper['utterances'] = utts\n",
    "    validate.append(helper)\n",
    "\n",
    "train_data['train'] = train\n",
    "train_data['validate'] = validate\n"
   ]
  },
  {
   "source": [
    "Save the training data into a json file.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cs_training_data.json', 'w') as file:\n",
    "    json.dump(train_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}