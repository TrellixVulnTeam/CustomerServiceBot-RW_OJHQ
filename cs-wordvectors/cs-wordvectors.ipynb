{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c9c193319ebd2a89754c1a4aa4516d58b41ef9df354ad04f80777c68efefc770"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using transfer learning to create a chatbot\n",
    "This file can be used if the repo is implemented in cloud, such as in a Colab notebook.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Train the model\n",
    "The train.py script imports a pretrained BERT model and trains it on a given dataset or the default dataset in Hugging Face's S3 bucket.   \n",
    "With the parameters as shown, the training should take about 30 minutes.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./hugging-face/train.py --dataset_path=\"cs_training_data.json\" --n_epochs=3 --train_batch_size=3 --valid_batch_size=3 "
   ]
  },
  {
   "source": [
    "Chat with the trained model using interact.py.   \n",
    "If a model_checkpoint is not specified, interact.py will reference a previously trained model from Hugging Face's S3 bucket.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-04 13:01:19.624228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\nINFO:./hugging-face/interact.py:Namespace(dataset_cache='./dataset_cache', dataset_path='', device='cuda', max_history=2, max_length=20, min_length=1, model='openai-gpt', model_checkpoint=\"'/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'\", no_sample=False, seed=0, temperature=0.7, top_k=0, top_p=0.9)\nINFO:./hugging-face/interact.py:Get pretrained model and tokenizer\nINFO:transformers.tokenization_utils:Model name ''/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'' not found in model shortcut name list (openai-gpt). Assuming ''/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'' is a path, a model identifier, or url to a directory containing tokenizer files.\nTraceback (most recent call last):\n  File \"./hugging-face/interact.py\", line 154, in <module>\n    run()\n  File \"./hugging-face/interact.py\", line 127, in run\n    tokenizer = tokenizer_class.from_pretrained(args.model_checkpoint)\n  File \"C:\\Users\\owner\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils.py\", line 390, in from_pretrained\n    return cls._from_pretrained(*inputs, **kwargs)\n  File \"C:\\Users\\owner\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\tokenization_utils.py\", line 493, in _from_pretrained\n    list(cls.vocab_files_names.values()),\nOSError: Model name ''/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'' was not found in tokenizers model name list (openai-gpt). We assumed ''/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.json', 'merges.txt'] but couldn't find such vocabulary files at this path or url.\n"
     ]
    }
   ],
   "source": [
    "!python ./hugging-face/interact.py --model_checkpoint '/content/runs/Apr03_19-59-03_b8f756943518_openai-gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}